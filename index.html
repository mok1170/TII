<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>D2TriPO-DETR: Dual-Decoder Triple-Parallel-Output Detection Transformer</title>
  <script src="https://cdn.tailwindcss.com"></script>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;600;800&display=swap" rel="stylesheet">
  <meta name="description" content="D2TriPO-DETR: Dual-Decoder Triple-Parallel-Output Detection Transformer" />
  <style>
    :root{--brand:#0f172a;--muted:#6b7280;--accent:#111827}
    html,body{height:100%}
    body{font-family:Inter,ui-sans-serif,system-ui,-apple-system,"Segoe UI",Roboto,'Helvetica Neue',Arial; background:#ffffff; color:var(--brand);}

    /* Page width control: leave side whitespace */
    .container{max-width:920px;margin-left:auto;margin-right:auto;padding-left:22px;padding-right:22px}

    /* Text justification: apply to content paragraphs but keep headings centered */
    body, p, li, td, th, figcaption, footer, nav { text-align: justify; text-justify: inter-word; }
    h1, .title-center { text-align: center; text-justify: none; }

    .shadow-soft{box-shadow:0 8px 30px rgba(17,24,39,0.06)}
    .glass{background:linear-gradient(180deg, rgba(255,255,255,0.95), rgba(250,250,250,0.95));backdrop-filter:blur(4px)}
    .figure-img{max-height:520px;object-fit:contain}
    .caption{color:var(--muted);font-size:0.95rem}
    header a.code-link{display:inline-block;padding:8px 14px;border-radius:10px;background:transparent;border:1px solid #e6e6e6;font-size:0.95rem}

    h1{font-weight:800; font-size:2.4rem; margin:0; line-height:1.05}
    .mute-small{color:var(--muted);font-size:0.95rem}

    /* Button style for paper/code/model */
    .action-btn{display:inline-flex;align-items:center;justify-content:center;gap:8px;padding:10px 18px;border-radius:14px;border:1px solid #e6e6e6;background:#111827;color:white;text-decoration:none;font-weight:600}
    .action-btn.ghost{background:#f8fafc;color:var(--brand);border:1px solid #e6e6e6}

    /* Responsive tweaks */
    @media (max-width:640px){ .action-btn{width:100%;padding:12px 16px;border-radius:10px} .btn-row{flex-direction:column;gap:10px} }
  </style>
</head>
<body class="antialiased text-slate-900">
  <!-- Top bar (keeps yesterday's style) -->
  <nav class="border-b py-3">
    <div class="container flex items-center justify-between">
      <div class="flex items-center gap-3">
        <div class="w-10 h-10 rounded-lg bg-gray-900 flex items-center justify-center text-white font-bold">D2</div>
        <div>
          <div class="text-sm font-semibold">D2TriPO-DETR</div>
          <div class="mute-small">Dual-Decoder Triple-Parallel-Output Detection Transformer</div>
        </div>
      </div>
      <div>
        <a class="code-link" href="https://github.com/Embodied-Soft-Intelligence/TII" target="_blank" rel="noopener noreferrer">Code</a>
      </div>
    </div>
  </nav>

  <header class="container py-10 text-center">
    <!-- Big bold title (centered) -->
    <h1 class="title-center">D2TriPO-DETR: Dual-Decoder Triple-Parallel-Output Detection Transformer</h1>
    <p class="mt-3 mute-small">Author(s): <span class="italic">(place author names here)</span></p>

    <!-- Button row (paper / code / model) under author line -->
    <div class="mt-5 flex justify-center items-center gap-4 btn-row">
      <a class="action-btn ghost" href="#" title="Paper link placeholder">Paper</a>
      <a class="action-btn" href="https://github.com/Embodied-Soft-Intelligence/TII" target="_blank" rel="noopener noreferrer">Code</a>
      <a class="action-btn ghost" href="#" title="Model link placeholder">Model</a>
    </div>

    <div class="mt-6 bg-white p-4 rounded shadow-soft text-left">
      <p class="leading-relaxed">Vision-based grasping, though widely employed for industrial and household applications, still struggles with object stacking scenarios. Current methods face three major challenges: <strong>1)</strong> limited inter-object relationship understanding, <strong>2)</strong> poor grasping adaptation across viewpoints, and <strong>3)</strong> error propagation. We propose <strong>D2TriPO-DETR</strong>, a dual-decoder transformer that outputs three parallel results — object detection, manipulation relationship, and grasp detection — using distributed attention perception and visual attention adaptation to address these issues. On the Visual Manipulation Relationship Dataset our method outperforms prior work across metrics and demonstrates strong real-world performance.</p>
    </div>
  </header>

  <main class="container pb-16">

    <!-- Fig 1 (no caption) -->
    <section id="fig1" class="mt-6">
      <div class="bg-white rounded-lg p-4 shadow-soft">
        <img src="https://raw.githubusercontent.com/mok1170/TII/main/Fig.%201.jpg" alt="Fig.1" class="w-full figure-img rounded" />
      </div>
    </section>

    <div class="my-8"></div>

    <!-- Fig 7 & description -->
    <section class="grid grid-cols-1 md:grid-cols-2 gap-6 items-start">
      <div class="bg-white rounded-lg p-4 shadow-soft text-center">
        <img src="https://raw.githubusercontent.com/mok1170/TII/main/Fig.%207.jpg" alt="Fig.7" class="w-full rounded figure-img" />
      </div>
      <div class="glass p-6 rounded-lg shadow-soft">
        <h3 class="font-semibold text-lg">Experiment setup</h3>
        <p class="mt-3 leading-relaxed">描述文字（在此处填写关于 Fig. 7 的说明）。</p>
      </div>
    </section>

    <!-- Fig 8 centered with description -->
    <section class="mt-10">
      <div class="bg-white rounded-lg p-6 shadow-soft">
        <img src="https://raw.githubusercontent.com/mok1170/TII/main/Fig.%208.jpg" alt="Fig.8" class="w-full figure-img rounded" />
        <p class="mt-4 leading-relaxed">To evaluate applicability to real-world grasping, we test configurations with 2–5 objects. For each object count we run five trials in both cluttered and stacked settings, yielding 40 experiments in total.</p>
      </div>
    </section>

    <!-- Tables side-by-side -->
    <section id="results" class="mt-12 grid grid-cols-1 lg:grid-cols-2 gap-6">
      <div class="bg-white p-6 rounded-lg shadow-soft overflow-auto">
        <h4 class="font-semibold mb-4">Model results</h4>
        <div class="rounded overflow-hidden border">
          <table class="w-full text-sm">
            <thead><tr><th class="px-4 py-2 text-left">Models</th><th class="px-4 py-2">Cluttered (%)</th><th class="px-4 py-2">Stacked (%)</th></tr></thead>
            <tbody>
              <tr class="odd:bg-white even:bg-slate-50"><td class="px-4 py-2">Mutli-Task CNN [8]</td><td class="px-4 py-2 text-center">90.60</td><td class="px-4 py-2 text-center">65.65</td></tr>
              <tr class="odd:bg-white even:bg-slate-50"><td class="px-4 py-2">SMTNet [30]</td><td class="px-4 py-2 text-center">86.13</td><td class="px-4 py-2 text-center">65.00</td></tr>
              <tr class="odd:bg-white even:bg-slate-50"><td class="px-4 py-2">EGNet [5]</td><td class="px-4 py-2 text-center">93.60</td><td class="px-4 py-2 text-center">69.60</td></tr>
              <tr class="font-semibold bg-gradient-to-r from-indigo-50 to-white"><td class="px-4 py-2">D2TriPO-DETR (Ours)</td><td class="px-4 py-2 text-center">95.71</td><td class="px-4 py-2 text-center">74.29</td></tr>
            </tbody>
          </table>
        </div>
      </div>

      <div class="bg-white p-6 rounded-lg shadow-soft overflow-auto">
        <h4 class="font-semibold mb-4">Per-object success rates</h4>
        <div class="rounded overflow-hidden border">
          <table class="w-full text-sm">
            <thead><tr><th class="px-4 py-2">Objects</th><th class="px-4 py-2">2</th><th class="px-4 py-2">3</th><th class="px-4 py-2">4</th><th class="px-4 py-2">5</th></tr></thead>
            <tbody>
              <tr class="odd:bg-white even:bg-slate-50"><td class="px-4 py-2">Cluttered Scenes</td><td class="px-4 py-2 text-center">100.00%</td><td class="px-4 py-2 text-center">100.00%</td><td class="px-4 py-2 text-center">95.00%</td><td class="px-4 py-2 text-center">92.00%</td></tr>
              <tr class="odd:bg-white even:bg-slate-50"><td class="px-4 py-2">Stacked Scenes</td><td class="px-4 py-2 text-center">90.00%</td><td class="px-4 py-2 text-center">73.33%</td><td class="px-4 py-2 text-center">75.00%</td><td class="px-4 py-2 text-center">68.00%</td></tr>
            </tbody>
          </table>
        </div>
      </div>
    </section>

    <!-- Concise descriptive paragraph -->
    <section class="mt-10 bg-white p-6 rounded-lg shadow-soft">
      <h4 class="font-semibold">Experiment summary</h4>
      <p class="mt-3 leading-relaxed">In the <strong>cluttered</strong> setting objects are placed separately to test detection among nearby items. The <strong>stacked</strong> setting introduces occlusions that require detection, grasp estimation, and reasoning about manipulation order. Our pipeline outputs detections, grasp candidates, and stacking relations in parallel; detections map to fixed queries to produce object indices and update an adjacency matrix P. If P is all-zero all objects are selectable; otherwise successive powers of P identify top-layer candidates. We keep grasp candidates with IoU &gt; 0.5, rank them by confidence, and execute high-confidence candidates via inverse kinematics with closed-loop verification, updating P after each grasp–place cycle. D2TriPO-DETR shows superior relation recognition and sequence-planning, enabling robust ordered grasping in stacked scenes.</p>
    </section>

    <!-- Fig 9 + Fig 10 sections -->
    <section id="real" class="mt-10 grid grid-cols-1 md:grid-cols-2 gap-6 items-start">
      <div class="bg-white p-6 rounded-lg shadow-soft">
        <img src="https://raw.githubusercontent.com/mok1170/TII/main/Fig.%209.jpg" alt="Fig.9" class="w-full rounded figure-img" />
      </div>
      <div class="glass p-6 rounded-lg shadow-soft">
        <h4 class="font-semibold">Stability evaluation</h4>
        <p class="mt-3 leading-relaxed">We selected representative scenarios with 2–5 objects and repeated each 30 times. The system shows only a modest drop in success rate as object count increases, maintaining high and stable performance across scales.</p>
      </div>

      <div class="order-last md:order-none bg-white p-6 rounded-lg shadow-soft">
        <img src="https://raw.githubusercontent.com/mok1170/TII/main/Fig.%2010.jpg" alt="Fig.10" class="w-full rounded figure-img" />
      </div>
      <div class="glass p-6 rounded-lg shadow-soft">
        <h4 class="font-semibold">Robustness under boundary ambiguity</h4>
        <p class="mt-3 leading-relaxed">Under severe occlusion, similar colors, and insertion cases we observe grasp success rates of roughly 65%, 70%, and 60% respectively. Although boundary ambiguity reduces performance, the model still detects objects and infers stacking relations for most scenes, enabling successful grasps.</p>
      </div>
    </section>

    <!-- Video -->
    <section id="video" class="mt-12 text-center">
      <div class="bg-white p-6 rounded-lg shadow-soft inline-block">
        <p class="text-sm text-gray-600 mb-3">Demonstration video — real robot experiments</p>
        <video controls class="w-full max-w-2xl rounded" src="https://raw.githubusercontent.com/mok1170/TII/main/2.mp4">Your browser does not support the video tag.</video>
      </div>
    </section>

    <footer class="mt-12 text-center text-sm text-gray-500">© 2025 D2TriPO-DETR — Research demonstration</footer>
  </main>

</body>
</html>
